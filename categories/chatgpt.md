# dylanhogg/awesome-python  [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)  

Hand-picked awesome Python libraries and frameworks, 
with an emphasis on data and machine learning, ranked by popularity score üêç  

Checkout the interactive version: [www.awesomepython.org](https://www.awesomepython.org/) üî•  


<a href="https://github.com/hwchase17)">hwchase17/</a><b><a href="https://github.com/hwchase17/langchain">langchain</a></b>  
‚ö° Building applications with LLMs through composability ‚ö°  
Score: 86/100, Stars: 35,082, Stars/week: 1186, Forks: 3,804  


<a href="https://github.com/hpcaitech)">hpcaitech/</a><b><a href="https://github.com/hpcaitech/colossalai">ColossalAI</a></b>  
[https://www.colossalai.org](https://www.colossalai.org)  
Making large AI models cheaper, faster and more accessible  
Score: 86/100, Stars: 29,218, Stars/week: 364, Forks: 3,388  


<a href="https://github.com/torantulino)">torantulino/</a><b><a href="https://github.com/torantulino/auto-gpt">Auto-GPT</a></b>  
[https://agpt.co](https://agpt.co)  
An experimental open-source attempt to make GPT-4 fully autonomous.  
Score: 86/100, Stars: 125,195, Stars/week: 15374, Forks: 24,650  


<a href="https://github.com/acheong08)">acheong08/</a><b><a href="https://github.com/acheong08/chatgpt">ChatGPT</a></b>  
Reverse engineered ChatGPT API  
Score: 85/100, Stars: 25,228, Stars/week: 1103, Forks: 4,107  


<a href="https://github.com/jerryjliu)">jerryjliu/</a><b><a href="https://github.com/jerryjliu/llama_index">llama_index</a></b>  
[https://gpt-index.readthedocs.io/en/latest/](https://gpt-index.readthedocs.io/en/latest/)  
LlamaIndex (GPT Index) is a project that provides a central interface to connect your LLM's with external data.  
Score: 85/100, Stars: 14,524, Stars/week: 532, Forks: 1,507  


<a href="https://github.com/laion-ai)">laion-ai/</a><b><a href="https://github.com/laion-ai/open-assistant">Open-Assistant</a></b>  
[https://open-assistant.io](https://open-assistant.io)  
OpenAssistant is a chat-based assistant that understands tasks, can interact with third-party systems, and retrieve information dynamically to do so.  
Score: 85/100, Stars: 31,805, Stars/week: 1484, Forks: 2,691  


<a href="https://github.com/ggerganov)">ggerganov/</a><b><a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a></b>  
Port of Facebook's LLaMA model in C/C++  
Score: 84/100, Stars: 25,942, Stars/week: 2882, Forks: 3,737  


<a href="https://github.com/acheong08)">acheong08/</a><b><a href="https://github.com/acheong08/edgegpt">EdgeGPT</a></b>  
Reverse engineered API of Microsoft's Bing Chat AI  
Score: 82/100, Stars: 6,354, Stars/week: 483, Forks: 653  


<a href="https://github.com/yoheinakajima)">yoheinakajima/</a><b><a href="https://github.com/yoheinakajima/babyagi">babyagi</a></b>  
GPT-4 powered task-driven autonomous agent  
Score: 79/100, Stars: 13,430, Stars/week: 2410, Forks: 1,848  


<a href="https://github.com/lm-sys)">lm-sys/</a><b><a href="https://github.com/lm-sys/fastchat">FastChat</a></b>  
An open platform for training, serving, and evaluating large languages. Release repo for Vicuna and FastChat-T5.  
Score: 78/100, Stars: 18,188, Stars/week: 2357, Forks: 1,989  


<a href="https://github.com/tloen)">tloen/</a><b><a href="https://github.com/tloen/alpaca-lora">alpaca-lora</a></b>  
Instruct-tune LLaMA on consumer hardware  
Score: 77/100, Stars: 12,285, Stars/week: 1433, Forks: 1,481  


<a href="https://github.com/thudm)">thudm/</a><b><a href="https://github.com/thudm/chatglm-6b">ChatGLM-6B</a></b>  
ChatGLM-6B: An Open Bilingual Dialogue Language Model | ÂºÄÊ∫êÂèåËØ≠ÂØπËØùËØ≠Ë®ÄÊ®°Âûã  
Score: 77/100, Stars: 22,783, Stars/week: 2658, Forks: 2,747  


<a href="https://github.com/xtekky)">xtekky/</a><b><a href="https://github.com/xtekky/gpt4free">gpt4free</a></b>  
[https://discord.gg/gpt4free](https://discord.gg/gpt4free)  
decentralising the Ai Industry, just some language model api's...  
Score: 75/100, Stars: 32,219, Stars/week: 5125, Forks: 8,003  


<a href="https://github.com/huggingface)">huggingface/</a><b><a href="https://github.com/huggingface/peft">peft</a></b>  
[https://huggingface.co/docs/peft](https://huggingface.co/docs/peft)  
ü§ó PEFT: State-of-the-art Parameter-Efficient Fine-Tuning.  
Score: 75/100, Stars: 5,139, Stars/week: 214, Forks: 362  


<a href="https://github.com/idea-research)">idea-research/</a><b><a href="https://github.com/idea-research/grounded-segment-anything">Grounded-Segment-Anything</a></b>  
Marrying Grounding DINO with Segment Anything & Stable Diffusion & Tag2Text & BLIP & Whisper & ChatBot - Automatically Detect , Segment and Generate Anything with Image, Text, and Audio Inputs  
Score: 75/100, Stars: 7,968, Stars/week: 1549, Forks: 658  


<a href="https://github.com/zilliztech)">zilliztech/</a><b><a href="https://github.com/zilliztech/gptcache">GPTCache</a></b>  
[https://gptcache.readthedocs.io](https://gptcache.readthedocs.io)  
GPTCache is a library for creating semantic cache to store responses from LLM queries.  
Score: 74/100, Stars: 2,981, Stars/week: 425, Forks: 182  


<a href="https://github.com/microsoft)">microsoft/</a><b><a href="https://github.com/microsoft/taskmatrix">TaskMatrix</a></b>  
Connects ChatGPT and a series of Visual Foundation Models to enable sending and receiving images during chatting.  
Score: 74/100, Stars: 32,497, Stars/week: 3203, Forks: 3,091  


<a href="https://github.com/optimalscale)">optimalscale/</a><b><a href="https://github.com/optimalscale/lmflow">LMFlow</a></b>  
[https://optimalscale.github.io/LMFlow/](https://optimalscale.github.io/LMFlow/)  
An Extensible Toolkit for Finetuning and Inference of Large Foundation Models. Large Model for All.  
Score: 74/100, Stars: 5,034, Stars/week: 766, Forks: 508  


<a href="https://github.com/nomic-ai)">nomic-ai/</a><b><a href="https://github.com/nomic-ai/gpt4all">gpt4all</a></b>  
gpt4all: an ecosystem of open-source chatbots trained on a massive collections of clean assistant data including code, stories and dialogue  
Score: 74/100, Stars: 37,443, Stars/week: 5697, Forks: 3,985  


<a href="https://github.com/lightning-ai)">lightning-ai/</a><b><a href="https://github.com/lightning-ai/lit-llama">lit-llama</a></b>  
Implementation of the LLaMA language model based on nanoGPT. Supports flash attention, Int8 and GPTQ 4bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed.  
Score: 74/100, Stars: 3,081, Stars/week: 422, Forks: 206  


<a href="https://github.com/microsoft)">microsoft/</a><b><a href="https://github.com/microsoft/semantic-kernel">semantic-kernel</a></b>  
[https://aka.ms/semantic-kernel](https://aka.ms/semantic-kernel)  
Integrate cutting-edge LLM technology quickly and easily into your apps  
Score: 74/100, Stars: 7,260, Stars/week: 686, Forks: 803  


<a href="https://github.com/blinkdl)">blinkdl/</a><b><a href="https://github.com/blinkdl/chatrwkv">ChatRWKV</a></b>  
ChatRWKV is like ChatGPT but powered by RWKV (100% RNN) language model, and open source.  
Score: 74/100, Stars: 6,653, Stars/week: 391, Forks: 460  


<a href="https://github.com/karpathy)">karpathy/</a><b><a href="https://github.com/karpathy/nanogpt">nanoGPT</a></b>  
The simplest, fastest repository for training/finetuning medium-sized GPTs.  
Score: 73/100, Stars: 19,688, Stars/week: 1020, Forks: 2,293  


<a href="https://github.com/haotian-liu)">haotian-liu/</a><b><a href="https://github.com/haotian-liu/llava">LLaVA</a></b>  
[https://llava.hliu.cc](https://llava.hliu.cc)  
Large Language-and-Vision Assistant built towards multimodal GPT-4 level capabilities.  
Score: 72/100, Stars: 2,264, Stars/week: 633, Forks: 149  


<a href="https://github.com/fauxpilot)">fauxpilot/</a><b><a href="https://github.com/fauxpilot/fauxpilot">fauxpilot</a></b>  
FauxPilot - an open-source alternative to GitHub Copilot server  
Score: 72/100, Stars: 11,822, Stars/week: 293, Forks: 484  


<a href="https://github.com/microsoft)">microsoft/</a><b><a href="https://github.com/microsoft/jarvis">JARVIS</a></b>  
JARVIS, a system to connect LLMs with ML community. Paper: https://arxiv.org/pdf/2303.17580.pdf  
Score: 72/100, Stars: 19,881, Stars/week: 3236, Forks: 1,595  


<a href="https://github.com/openai)">openai/</a><b><a href="https://github.com/openai/chatgpt-retrieval-plugin">chatgpt-retrieval-plugin</a></b>  
The ChatGPT Retrieval Plugin lets you easily search and find personal or work documents by asking questions in everyday language.  
Score: 71/100, Stars: 15,794, Stars/week: 2211, Forks: 2,374  


<a href="https://github.com/rasahq)">rasahq/</a><b><a href="https://github.com/rasahq/rasa">rasa</a></b>  
[https://rasa.com/docs/rasa/](https://rasa.com/docs/rasa/)  
üí¨   Open source machine learning framework to automate text- and voice-based conversations: NLU, dialogue management, connect to Slack, Facebook, and more - Create chatbots and voice assistants  
Score: 71/100, Stars: 16,089, Stars/week: 46, Forks: 4,321  


<a href="https://github.com/facebookresearch)">facebookresearch/</a><b><a href="https://github.com/facebookresearch/llama">llama</a></b>  
Inference code for LLaMA models  
Score: 70/100, Stars: 20,446, Stars/week: 1645, Forks: 3,281  


<a href="https://github.com/databrickslabs)">databrickslabs/</a><b><a href="https://github.com/databrickslabs/dolly">dolly</a></b>  
[https://www.databricks.com/blog/2023/03/24/hello-dolly-democratizing-magic-chatgpt-open-models.html](https://www.databricks.com/blog/2023/03/24/hello-dolly-democratizing-magic-chatgpt-open-models.html)  
Databricks‚Äô Dolly, a large language model trained on the Databricks Machine Learning Platform  
Score: 70/100, Stars: 9,641, Stars/week: 1377, Forks: 971  


<a href="https://github.com/mlc-ai)">mlc-ai/</a><b><a href="https://github.com/mlc-ai/web-llm">web-llm</a></b>  
[https://mlc.ai/web-llm](https://mlc.ai/web-llm)  
Bringing large-language models and chat to web browsers. Everything runs inside the browser with no server support.  
Score: 70/100, Stars: 5,282, Stars/week: 1274, Forks: 274  


<a href="https://github.com/vision-cair)">vision-cair/</a><b><a href="https://github.com/vision-cair/minigpt-4">MiniGPT-4</a></b>  
[https://minigpt-4.github.io](https://minigpt-4.github.io)  
MiniGPT-4: Enhancing Vision-language Understanding with Advanced Large Language Models  
Score: 70/100, Stars: 18,033, Stars/week: 4675, Forks: 1,968  


<a href="https://github.com/zrrskywalker)">zrrskywalker/</a><b><a href="https://github.com/zrrskywalker/llama-adapter">LLaMA-Adapter</a></b>  
Fine-tuning LLaMA to follow Instructions within 1 Hour and 1.2M Parameters  
Score: 70/100, Stars: 3,164, Stars/week: 410, Forks: 194  


<a href="https://github.com/tatsu-lab)">tatsu-lab/</a><b><a href="https://github.com/tatsu-lab/stanford_alpaca">stanford_alpaca</a></b>  
[https://crfm.stanford.edu/2023/03/13/alpaca.html](https://crfm.stanford.edu/2023/03/13/alpaca.html)  
Code and documentation to train Stanford's Alpaca models, and generate the data.  
Score: 68/100, Stars: 22,887, Stars/week: 2543, Forks: 3,277  


<a href="https://github.com/ravenscroftj)">ravenscroftj/</a><b><a href="https://github.com/ravenscroftj/turbopilot">turbopilot</a></b>  
Turbopilot is an open source large-language-model based code completion engine that runs locally on CPU  
Score: 68/100, Stars: 3,367, Stars/week: 714, Forks: 109  


<a href="https://github.com/abetlen)">abetlen/</a><b><a href="https://github.com/abetlen/llama-cpp-python">llama-cpp-python</a></b>  
[https://abetlen.github.io/llama-cpp-python/](https://abetlen.github.io/llama-cpp-python/)  
Python bindings for llama.cpp  
Score: 68/100, Stars: 932, Stars/week: 130, Forks: 109  


<a href="https://github.com/h2oai)">h2oai/</a><b><a href="https://github.com/h2oai/h2o-llmstudio">h2o-llmstudio</a></b>  
[https://h2o.ai](https://h2o.ai)  
H2O LLM Studio - a framework and no-code GUI for fine-tuning LLMs  
Score: 68/100, Stars: 1,104, Stars/week: 309, Forks: 88  


<a href="https://github.com/deepset-ai)">deepset-ai/</a><b><a href="https://github.com/deepset-ai/haystack">haystack</a></b>  
[https://haystack.deepset.ai](https://haystack.deepset.ai)  
:mag: Haystack is an open source NLP framework to interact with your data using Transformer models and LLMs (GPT-4, ChatGPT and alike). Haystack offers production-ready tools to quickly build complex decision making, question answering, semantic search, text generation applications, and more.  
Score: 67/100, Stars: 8,550, Stars/week: 46, Forks: 1,185  


<a href="https://github.com/nomic-ai)">nomic-ai/</a><b><a href="https://github.com/nomic-ai/pygpt4all">pygpt4all</a></b>  
[https://nomic-ai.github.io/pygpt4all/](https://nomic-ai.github.io/pygpt4all/)  
Official supported Python bindings for llama.cpp + gpt4all  
Score: 67/100, Stars: 930, Stars/week: 166, Forks: 144  


<a href="https://github.com/mmabrouk)">mmabrouk/</a><b><a href="https://github.com/mmabrouk/chatgpt-wrapper">chatgpt-wrapper</a></b>  
API for interacting with ChatGPT and GPT4 using Python and from Shell.  
Score: 66/100, Stars: 3,195, Stars/week: 139, Forks: 412  


<a href="https://github.com/togethercomputer)">togethercomputer/</a><b><a href="https://github.com/togethercomputer/redpajama-data">RedPajama-Data</a></b>  
The RedPajama-Data repository contains code for preparing large datasets for training large language models.  
Score: 66/100, Stars: 2,336, Stars/week: 584, Forks: 177  


<a href="https://github.com/mayooear)">mayooear/</a><b><a href="https://github.com/mayooear/gpt4-pdf-chatbot-langchain">gpt4-pdf-chatbot-langchain</a></b>  
[https://www.youtube.com/watch?v=ih9PBGVVOO4](https://www.youtube.com/watch?v=ih9PBGVVOO4)  
GPT4 & LangChain Chatbot for large PDF docs  
Score: 66/100, Stars: 9,730, Stars/week: 1216, Forks: 1,842  


<a href="https://github.com/freedomintelligence)">freedomintelligence/</a><b><a href="https://github.com/freedomintelligence/llmzoo">LLMZoo</a></b>  
‚ö°LLM Zoo is a project that provides data, models, and evaluation benchmark for large language models.‚ö°  
Score: 65/100, Stars: 1,760, Stars/week: 300, Forks: 92  


<a href="https://github.com/nvidia)">nvidia/</a><b><a href="https://github.com/nvidia/nemo-guardrails">NeMo-Guardrails</a></b>  
NeMo Guardrails is an open-source toolkit for easily adding programmable guardrails to LLM-based conversational systems.  
Score: 65/100, Stars: 1,182, Stars/week: 344, Forks: 64  


<a href="https://github.com/juncongmoo)">juncongmoo/</a><b><a href="https://github.com/juncongmoo/pyllama">pyllama</a></b>  
LLaMA: Open and Efficient Foundation Language Models  
Score: 64/100, Stars: 1,853, Stars/week: 177, Forks: 209  


<a href="https://github.com/thudm)">thudm/</a><b><a href="https://github.com/thudm/codegeex">CodeGeeX</a></b>  
[https://codegeex.cn](https://codegeex.cn)  
CodeGeeX: An Open Multilingual Code Generation Model  
Score: 64/100, Stars: 4,848, Stars/week: 143, Forks: 326  


<a href="https://github.com/instruction-tuning-with-gpt-4)">instruction-tuning-with-gpt-4/</a><b><a href="https://github.com/instruction-tuning-with-gpt-4/gpt-4-llm">GPT-4-LLM</a></b>  
[https://instruction-tuning-with-gpt-4.github.io/](https://instruction-tuning-with-gpt-4.github.io/)  
Instruction Tuning with GPT-4  
Score: 64/100, Stars: 2,447, Stars/week: 475, Forks: 176  


<a href="https://github.com/nlpxucan)">nlpxucan/</a><b><a href="https://github.com/nlpxucan/wizardlm">WizardLM</a></b>  
WizardLM: Empowering Large Pre-Trained Language Models to Follow Complex Instructions  
Score: 62/100, Stars: 1,337, Stars/week: 492, Forks: 86  


<a href="https://github.com/eleutherai)">eleutherai/</a><b><a href="https://github.com/eleutherai/gpt-neox">gpt-neox</a></b>  
An implementation of model parallel autoregressive transformers on GPUs, based on the DeepSpeed library.  
Score: 62/100, Stars: 5,241, Stars/week: 42, Forks: 733  


<a href="https://github.com/openlm-research)">openlm-research/</a><b><a href="https://github.com/openlm-research/open_llama">open_llama</a></b>  
OpenLLaMA: An Open Reproduction of LLaMA  
Score: 62/100, Stars: 2,484, Stars/week: 1242, Forks: 80  


<a href="https://github.com/microsoft)">microsoft/</a><b><a href="https://github.com/microsoft/biogpt">BioGPT</a></b>  
microsoft/BioGPT  
Score: 58/100, Stars: 3,815, Stars/week: 98, Forks: 381  


<a href="https://github.com/lvwerra)">lvwerra/</a><b><a href="https://github.com/lvwerra/trl">trl</a></b>  
[http://hf.co/docs/trl](http://hf.co/docs/trl)  
Train transformer language models with reinforcement learning.  
Score: 58/100, Stars: 3,262, Stars/week: 20, Forks: 350  


<a href="https://github.com/oliveirabruno01)">oliveirabruno01/</a><b><a href="https://github.com/oliveirabruno01/babyagi-asi">babyagi-asi</a></b>  
BabyAGI: an Autonomous and Self-Improving agent, or BASI  
Score: 57/100, Stars: 583, Stars/week: 116, Forks: 55  


<a href="https://github.com/thudm)">thudm/</a><b><a href="https://github.com/thudm/glm-130b">GLM-130B</a></b>  
GLM-130B: An Open Bilingual Pre-Trained Model (ICLR 2023)  
Score: 57/100, Stars: 5,247, Stars/week: 130, Forks: 377  


<a href="https://github.com/eth-sri)">eth-sri/</a><b><a href="https://github.com/eth-sri/lmql">lmql</a></b>  
[https://lmql.ai](https://lmql.ai)  
A query language for programming (large) language models.   
Score: 56/100, Stars: 815, Stars/week: 33, Forks: 43  


<a href="https://github.com/lucidrains)">lucidrains/</a><b><a href="https://github.com/lucidrains/toolformer-pytorch">toolformer-pytorch</a></b>  
Implementation of Toolformer, Language Models That Can Use Tools, by MetaAI  
Score: 55/100, Stars: 1,291, Stars/week: 99, Forks: 71  


<a href="https://github.com/karpathy)">karpathy/</a><b><a href="https://github.com/karpathy/mingpt">minGPT</a></b>  
A minimal PyTorch re-implementation of the OpenAI GPT (Generative Pretrained Transformer) training  
Score: 55/100, Stars: 15,049, Stars/week: 105, Forks: 1,749  


<a href="https://github.com/chatarena)">chatarena/</a><b><a href="https://github.com/chatarena/chatarena">chatarena</a></b>  
ChatArena (or Chat Arena) is a Multi-Agent Language Game Environments for LLMs. The goal is to develop communication and collaboration capabilities of AIs.  
Score: 54/100, Stars: 699, Stars/week: 73, Forks: 50  


<a href="https://github.com/microsoft)">microsoft/</a><b><a href="https://github.com/microsoft/torchscale">torchscale</a></b>  
[https://aka.ms/nlpagi](https://aka.ms/nlpagi)  
Transformers at any scale  
Score: 52/100, Stars: 1,622, Stars/week: 64, Forks: 89  


<a href="https://github.com/nvidia)">nvidia/</a><b><a href="https://github.com/nvidia/megatron-lm">Megatron-LM</a></b>  
Ongoing research training transformer models at scale  
Score: 52/100, Stars: 4,880, Stars/week: 22, Forks: 986  


<a href="https://github.com/microsoft)">microsoft/</a><b><a href="https://github.com/microsoft/lmops">LMOps</a></b>  
[https://aka.ms/nlpagi](https://aka.ms/nlpagi)  
General technology for enabling AI capabilities w/ LLMs and MLLMs  
Score: 51/100, Stars: 1,492, Stars/week: 69, Forks: 79  


<a href="https://github.com/run-llama)">run-llama/</a><b><a href="https://github.com/run-llama/llama-lab">llama-lab</a></b>  
Llama Lab is a repo dedicated to building cutting-edge projects using LlamaIndex  
Score: 51/100, Stars: 490, Stars/week: 122, Forks: 33  


<a href="https://github.com/microsoft)">microsoft/</a><b><a href="https://github.com/microsoft/lora">LoRA</a></b>  
[https://arxiv.org/abs/2106.09685](https://arxiv.org/abs/2106.09685)  
Code for loralib, an implementation of "LoRA: Low-Rank Adaptation of Large Language Models"  
Score: 50/100, Stars: 3,476, Stars/week: 35, Forks: 181  


<a href="https://github.com/openai)">openai/</a><b><a href="https://github.com/openai/gpt-2">gpt-2</a></b>  
[https://openai.com/blog/better-language-models/](https://openai.com/blog/better-language-models/)  
Code for the paper "Language Models are Unsupervised Multitask Learners"  
Score: 50/100, Stars: 18,953, Stars/week: 85, Forks: 4,833  


<a href="https://github.com/ofa-sys)">ofa-sys/</a><b><a href="https://github.com/ofa-sys/ofa">OFA</a></b>  
Official repository of OFA (ICML 2022). Paper: OFA: Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework  
Score: 50/100, Stars: 1,837, Stars/week: 27, Forks: 216  


<a href="https://github.com/yizhongw)">yizhongw/</a><b><a href="https://github.com/yizhongw/self-instruct">self-instruct</a></b>  
Aligning pretrained language models with instruction data generated by themselves.  
Score: 50/100, Stars: 2,103, Stars/week: 102, Forks: 258  


<a href="https://github.com/eleutherai)">eleutherai/</a><b><a href="https://github.com/eleutherai/lm-evaluation-harness">lm-evaluation-harness</a></b>  
A framework for few-shot evaluation of autoregressive language models.  
Score: 46/100, Stars: 1,055, Stars/week: 7, Forks: 294  


<a href="https://github.com/openai)">openai/</a><b><a href="https://github.com/openai/gpt-discord-bot">gpt-discord-bot</a></b>  
Example Discord bot written in Python that uses the completions API to have conversations with the `text-davinci-003` model, and the moderations API to filter the messages.  
Score: 44/100, Stars: 1,413, Stars/week: 69, Forks: 536  


<a href="https://github.com/eleutherai)">eleutherai/</a><b><a href="https://github.com/eleutherai/gpt-neo">gpt-neo</a></b>  
[https://www.eleuther.ai](https://www.eleuther.ai)  
An implementation of model parallel GPT-2 and GPT-3-style models using the mesh-tensorflow library.  
Score: 43/100, Stars: 7,764, Stars/week: 52, Forks: 874  


<a href="https://github.com/minimaxir)">minimaxir/</a><b><a href="https://github.com/minimaxir/aitextgen">aitextgen</a></b>  
[https://docs.aitextgen.io](https://docs.aitextgen.io)  
A robust Python tool for text-based AI training and generation using GPT-2.  
Score: 43/100, Stars: 1,759, Stars/week: 10, Forks: 207  


<a href="https://github.com/explosion)">explosion/</a><b><a href="https://github.com/explosion/spacy-transformers">spacy-transformers</a></b>  
[https://spacy.io/usage/embeddings-transformers](https://spacy.io/usage/embeddings-transformers)  
üõ∏ Use pretrained transformers like BERT, XLNet and GPT-2 in spaCy  
Score: 42/100, Stars: 1,241, Stars/week: 6, Forks: 160  


<a href="https://github.com/ist-daslab)">ist-daslab/</a><b><a href="https://github.com/ist-daslab/gptq">gptq</a></b>  
[https://arxiv.org/abs/2210.17323](https://arxiv.org/abs/2210.17323)  
Code for the ICLR 2023 paper "GPTQ: Accurate Post-training Quantization of Generative Pretrained Transformers".  
Score: 42/100, Stars: 686, Stars/week: 23, Forks: 59  


<a href="https://github.com/hazyresearch)">hazyresearch/</a><b><a href="https://github.com/hazyresearch/h3">H3</a></b>  
Language Modeling with the H3 State Space Model  
Score: 41/100, Stars: 407, Stars/week: 21, Forks: 39  


<a href="https://github.com/bigscience-workshop)">bigscience-workshop/</a><b><a href="https://github.com/bigscience-workshop/megatron-deepspeed">Megatron-DeepSpeed</a></b>  
Ongoing research training transformer language models at scale, including: BERT & GPT-2  
Score: 40/100, Stars: 723, Stars/week: 7, Forks: 149  


<a href="https://github.com/minimaxir)">minimaxir/</a><b><a href="https://github.com/minimaxir/gpt-2-simple">gpt-2-simple</a></b>  
Python package to easily retrain OpenAI's GPT-2 text-generating model on new texts  
Score: 40/100, Stars: 3,259, Stars/week: 15, Forks: 666  


<a href="https://github.com/microsoft)">microsoft/</a><b><a href="https://github.com/microsoft/megatron-deepspeed">Megatron-DeepSpeed</a></b>  
Ongoing research training transformer language models at scale, including: BERT & GPT-2  
Score: 39/100, Stars: 570, Stars/week: 6, Forks: 117  


<a href="https://github.com/kbressem)">kbressem/</a><b><a href="https://github.com/kbressem/medalpaca">medAlpaca</a></b>  
LLM finetuned for medical question answering  
Score: 38/100, Stars: 136, Stars/week: 21, Forks: 10  


<a href="https://github.com/lucidrains)">lucidrains/</a><b><a href="https://github.com/lucidrains/medical-chatgpt">medical-chatgpt</a></b>  
Implementation of ChatGPT, but tailored towards primary care medicine, with the reward being able to collect patient histories in a thorough and efficient manner and come up with a reasonable differential diagnosis  
Score: 35/100, Stars: 281, Stars/week: 12, Forks: 27  


<a href="https://github.com/muennighoff)">muennighoff/</a><b><a href="https://github.com/muennighoff/sgpt">sgpt</a></b>  
SGPT: GPT Sentence Embeddings for Semantic Search  
Score: 34/100, Stars: 463, Stars/week: 7, Forks: 30  


<a href="https://github.com/microsoft)">microsoft/</a><b><a href="https://github.com/microsoft/chatgpt-robot-manipulation-prompts">ChatGPT-Robot-Manipulation-Prompts</a></b>  
microsoft/ChatGPT-Robot-Manipulation-Prompts  
Score: 34/100, Stars: 172, Stars/week: 33, Forks: 12  


<a href="https://github.com/keirp)">keirp/</a><b><a href="https://github.com/keirp/automatic_prompt_engineer">automatic_prompt_engineer</a></b>  
Large Language Models Are Human-Level Prompt Engineers  
Score: 32/100, Stars: 452, Stars/week: 15, Forks: 38  


<a href="https://github.com/reasoning-machines)">reasoning-machines/</a><b><a href="https://github.com/reasoning-machines/pal">pal</a></b>  
[https://reasonwithpal.com](https://reasonwithpal.com)  
PaL: Program-Aided Language Models  
Score: 32/100, Stars: 253, Stars/week: 10, Forks: 23  


<a href="https://github.com/conceptofmind)">conceptofmind/</a><b><a href="https://github.com/conceptofmind/toolformer">toolformer</a></b>  
Open-source implementation of Toolformer: Language Models Can Teach Themselves to Use Tools  
Score: 31/100, Stars: 201, Stars/week: 16, Forks: 24  


<a href="https://github.com/openai)">openai/</a><b><a href="https://github.com/openai/gpt-2-output-dataset">gpt-2-output-dataset</a></b>  
Dataset of GPT-2 outputs for research in detection, biases, and more  
Score: 28/100, Stars: 1,690, Stars/week: 8, Forks: 491  


<a href="https://github.com/bigscience-workshop)">bigscience-workshop/</a><b><a href="https://github.com/bigscience-workshop/t-zero">t-zero</a></b>  
Reproduce results and replicate training fo T0 (Multitask Prompted Training Enables Zero-Shot Task Generalization)  
Score: 27/100, Stars: 378, Stars/week: 5, Forks: 52  


<a href="https://github.com/larsbaunwall)">larsbaunwall/</a><b><a href="https://github.com/larsbaunwall/bricky">bricky</a></b>  
Haystack/OpenAI based chatbot curating a custom knowledgebase  
Score: 27/100, Stars: 76, Stars/week: 5, Forks: 11  


<a href="https://github.com/openai)">openai/</a><b><a href="https://github.com/openai/image-gpt">image-gpt</a></b>  
Archived. Code and models from the paper "Generative Pretraining from Pixels"  
Score: 24/100, Stars: 1,874, Stars/week: 11, Forks: 352  


<a href="https://github.com/salesforce)">salesforce/</a><b><a href="https://github.com/salesforce/jaxformer">jaxformer</a></b>  
Minimal library to train LLMs on TPU in JAX with pjit().  
Score: 23/100, Stars: 186, Stars/week: 5, Forks: 25  


<a href="https://github.com/openai)">openai/</a><b><a href="https://github.com/openai/finetune-transformer-lm">finetune-transformer-lm</a></b>  
[https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf)  
Code and model for the paper "Improving Language Understanding by Generative Pre-Training"  
Score: 22/100, Stars: 1,826, Stars/week: 7, Forks: 455  


<a href="https://github.com/anthropics)">anthropics/</a><b><a href="https://github.com/anthropics/evals">evals</a></b>  
Model-Written Evaluation Datasets  
Score: 18/100, Stars: 133, Stars/week: 6, Forks: 9  


<a href="https://github.com/ai21labs)">ai21labs/</a><b><a href="https://github.com/ai21labs/in-context-ralm">in-context-ralm</a></b>  
In-Context Retrieval-Augmented Language Models  
Score: 16/100, Stars: 77, Stars/week: 5, Forks: 8  


<a href="https://github.com/qanastek)">qanastek/</a><b><a href="https://github.com/qanastek/drbert">DrBERT</a></b>  
[https://drbert.univ-avignon.fr/](https://drbert.univ-avignon.fr/)  
DrBERT: A Robust Pre-trained Model in French for Biomedical and Clinical domains  
Score: 10/100, Stars: 8, Stars/week: 0, Forks: 0  


---  

Checkout the interactive version: [www.awesomepython.org](https://www.awesomepython.org/) üî•  


Please raise <a href="https://github.com/dylanhogg/awesome-python/issues">a new issue</a> to suggest a Python repo that you would like to see added.  


This list was updated on 2023-05-12