# Crazy Awesome Python
A selection of 25 curated chatgpt Python libraries and frameworks ordered by stars.  

Checkout the interactive version that you can filter and sort: 
[https://www.awesomepython.org/](https://www.awesomepython.org/)  


### [ChatGPT](https://github.com/acheong08/chatgpt) by [acheong08](https://github.com/acheong08)  
ChatGPT: Reverse engineered ChatGPT API  
[https://github.com/acheong08/chatgpt](https://github.com/acheong08/chatgpt)  
1359 stars per week over 16 weeks  
22,134 stars, 3,506 forks, 228 watches  
created 2022-12-03, last commit 2023-03-26, main language Python  
<sub><sup>chatgpt, cli, gpt-35-turbo, gptchat, pypi-package, revchatgpt</sup></sub>


### [Open-Assistant](https://github.com/laion-ai/open-assistant) by [laion-ai](https://github.com/laion-ai)  
Open-Assistant: OpenAssistant is a chat-based assistant that understands tasks, can interact with third-party systems, and retrieve information dynamically to do so.  
[https://open-assistant.io](https://open-assistant.io)  
[https://github.com/laion-ai/open-assistant](https://github.com/laion-ai/open-assistant)  
1335 stars per week over 14 weeks  
19,837 stars, 1,493 forks, 292 watches  
created 2022-12-13, last commit 2023-03-26, main language Python  
<sub><sup>ai, assistant, chatgpt, discord-bot, language-model, machine-learning, nextjs, rlhf</sup></sub>


### [EdgeGPT](https://github.com/acheong08/edgegpt) by [acheong08](https://github.com/acheong08)  
EdgeGPT: Reverse engineered API of Microsoft's Bing Chat AI  
[https://github.com/acheong08/edgegpt](https://github.com/acheong08/edgegpt)  
710 stars per week over 6 weeks  
4,668 stars, 453 forks, 48 watches  
created 2023-02-09, last commit 2023-03-25, main language Python  
<sub><sup>bing-ai, binggpt, chatgpt, edge, edgegpt, gpt, reverse-engineering</sup></sub>


### [visual-chatgpt](https://github.com/microsoft/visual-chatgpt) by [microsoft](https://github.com/microsoft)  
visual-chatgpt: Official repo for the paper: Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models  
[https://github.com/microsoft/visual-chatgpt](https://github.com/microsoft/visual-chatgpt)  
7391 stars per week over 3 weeks  
26,398 stars, 2,297 forks, 223 watches  
created 2023-03-02, last commit 2023-03-22, main language Python  


### [alpaca-lora](https://github.com/tloen/alpaca-lora) by [tloen](https://github.com/tloen)  
alpaca-lora: Instruct-tune LLaMA on consumer hardware  
[https://github.com/tloen/alpaca-lora](https://github.com/tloen/alpaca-lora)  
3078 stars per week over 2 weeks  
6,157 stars, 693 forks, 78 watches  
created 2023-03-13, last commit 2023-03-24, main language Jupyter Notebook  


### [stanford_alpaca](https://github.com/tatsu-lab/stanford_alpaca) by [tatsu-lab](https://github.com/tatsu-lab)  
stanford_alpaca: Code and documentation to train Stanford's Alpaca models, and generate the data.  
[https://crfm.stanford.edu/alpaca/](https://crfm.stanford.edu/alpaca/)  
[https://github.com/tatsu-lab/stanford_alpaca](https://github.com/tatsu-lab/stanford_alpaca)  
6121 stars per week over 2 weeks  
14,867 stars, 1,973 forks, 212 watches  
created 2023-03-10, last commit 2023-03-25, main language Python  
<sub><sup>deep-learning, instruction-following, language-model</sup></sub>


### [haystack](https://github.com/deepset-ai/haystack) by [deepset-ai](https://github.com/deepset-ai)  
haystack: :mag: Haystack is an open source NLP framework to interact with your data using Transformer models and LLMs (GPT-3 and alike). Haystack offers production-ready tools to quickly build ChatGPT-like question answering, semantic search, text generation, and more.  
[https://haystack.deepset.ai](https://haystack.deepset.ai)  
[https://github.com/deepset-ai/haystack](https://github.com/deepset-ai/haystack)  
43 stars per week over 175 weeks  
7,551 stars, 1,108 forks, 102 watches  
created 2019-11-14, last commit 2023-03-24, main language Python  
<sub><sup>ai, bert, chatgpt, elasticsearch, generative-ai, gpt-3, information-retrieval, language-model, large-language-models, machine-learning, natural-language-processing, nlp, pytorch, question-answering, semantic-search, squad, summarization, transfer-learning, transformers</sup></sub>


### [BioGPT](https://github.com/microsoft/biogpt) by [microsoft](https://github.com/microsoft)  
microsoft/biogpt  
[https://github.com/microsoft/biogpt](https://github.com/microsoft/biogpt)  
111 stars per week over 32 weeks  
3,552 stars, 347 forks, 65 watches  
created 2022-08-15, last commit 2023-02-13, main language Python  


### [gpt-neox](https://github.com/eleutherai/gpt-neox) by [eleutherai](https://github.com/eleutherai)  
gpt-neox: An implementation of model parallel autoregressive transformers on GPUs, based on the DeepSpeed library.  
[https://github.com/eleutherai/gpt-neox](https://github.com/eleutherai/gpt-neox)  
38 stars per week over 117 weeks  
4,492 stars, 604 forks, 98 watches  
created 2020-12-22, last commit 2023-03-26, main language Python  
<sub><sup>deepspeed-library, gpt-3, language-model, transformers</sup></sub>


### [minGPT](https://github.com/karpathy/mingpt) by [karpathy](https://github.com/karpathy)  
minGPT: A minimal PyTorch re-implementation of the OpenAI GPT (Generative Pretrained Transformer) training  
[https://github.com/karpathy/mingpt](https://github.com/karpathy/mingpt)  
100 stars per week over 136 weeks  
13,654 stars, 1,584 forks, 230 watches  
created 2020-08-17, last commit 2023-01-08, main language Python  


### [gpt-2](https://github.com/openai/gpt-2) by [openai](https://github.com/openai)  
gpt-2: Code for the paper "Language Models are Unsupervised Multitask Learners"  
[https://openai.com/blog/better-language-models/](https://openai.com/blog/better-language-models/)  
[https://github.com/openai/gpt-2](https://github.com/openai/gpt-2)  
84 stars per week over 215 weeks  
18,115 stars, 4,550 forks, 611 watches  
created 2019-02-11, last commit 2020-12-02, main language Python  
<sub><sup>paper</sup></sub>


### [Megatron-LM](https://github.com/nvidia/megatron-lm) by [nvidia](https://github.com/nvidia)  
Megatron-LM: Ongoing research training transformer models at scale  
[https://github.com/nvidia/megatron-lm](https://github.com/nvidia/megatron-lm)  
20 stars per week over 209 weeks  
4,224 stars, 855 forks, 99 watches  
created 2019-03-21, last commit 2023-01-11, main language Python  


### [gpt-discord-bot](https://github.com/openai/gpt-discord-bot) by [openai](https://github.com/openai)  
gpt-discord-bot: Example Discord bot written in Python that uses the completions API to have conversations with the `text-davinci-003` model, and the moderations API to filter the messages.  
[https://github.com/openai/gpt-discord-bot](https://github.com/openai/gpt-discord-bot)  
88 stars per week over 13 weeks  
1,217 stars, 440 forks, 25 watches  
created 2022-12-21, last commit 2023-02-08, main language Python  


### [spacy-transformers](https://github.com/explosion/spacy-transformers) by [explosion](https://github.com/explosion)  
spacy-transformers: ðŸ›¸ Use pretrained transformers like BERT, XLNet and GPT-2 in spaCy  
[https://spacy.io/usage/embeddings-transformers](https://spacy.io/usage/embeddings-transformers)  
[https://github.com/explosion/spacy-transformers](https://github.com/explosion/spacy-transformers)  
6.37 stars per week over 191 weeks  
1,219 stars, 156 forks, 32 watches  
created 2019-07-26, last commit 2023-03-24, main language Python  
<sub><sup>bert, google, gpt-2, huggingface, language-model, machine-learning, natural-language-processing, natural-language-understanding, nlp, openai, pytorch, pytorch-model, spacy, spacy-extension, spacy-pipeline, transfer-learning, xlnet</sup></sub>


### [gpt-neo](https://github.com/eleutherai/gpt-neo) by [eleutherai](https://github.com/eleutherai)  
gpt-neo: An implementation of model parallel GPT-2 and GPT-3-style models using the mesh-tensorflow library.  
[https://www.eleuther.ai](https://www.eleuther.ai)  
[https://github.com/eleutherai/gpt-neo](https://github.com/eleutherai/gpt-neo)  
52 stars per week over 142 weeks  
7,446 stars, 770 forks, 171 watches  
created 2020-07-05, last commit 2022-02-25, main language Python  
<sub><sup>gpt, gpt-2, gpt-3, language-model, transformers</sup></sub>


### [aitextgen](https://github.com/minimaxir/aitextgen) by [minimaxir](https://github.com/minimaxir)  
aitextgen: A robust Python tool for text-based AI training and generation using GPT-2.  
[https://docs.aitextgen.io](https://docs.aitextgen.io)  
[https://github.com/minimaxir/aitextgen](https://github.com/minimaxir/aitextgen)  
10 stars per week over 169 weeks  
1,720 stars, 199 forks, 39 watches  
created 2019-12-29, last commit 2023-03-16, main language Python  


### [gpt-2-simple](https://github.com/minimaxir/gpt-2-simple) by [minimaxir](https://github.com/minimaxir)  
gpt-2-simple: Python package to easily retrain OpenAI's GPT-2 text-generating model on new texts  
[https://github.com/minimaxir/gpt-2-simple](https://github.com/minimaxir/gpt-2-simple)  
15 stars per week over 206 weeks  
3,206 stars, 656 forks, 74 watches  
created 2019-04-13, last commit 2022-05-22, main language Python  
<sub><sup>openai, tensorflow, text-generation, textgenrnn</sup></sub>


### [lm-evaluation-harness](https://github.com/eleutherai/lm-evaluation-harness) by [eleutherai](https://github.com/eleutherai)  
lm-evaluation-harness: A framework for few-shot evaluation of autoregressive language models.  
[https://github.com/eleutherai/lm-evaluation-harness](https://github.com/eleutherai/lm-evaluation-harness)  
4.53 stars per week over 134 weeks  
609 stars, 211 forks, 16 watches  
created 2020-08-28, last commit 2023-03-24, main language Python  


### [Megatron-DeepSpeed](https://github.com/bigscience-workshop/megatron-deepspeed) by [bigscience-workshop](https://github.com/bigscience-workshop)  
Megatron-DeepSpeed: Ongoing research training transformer language models at scale, including: BERT & GPT-2  
[https://github.com/bigscience-workshop/megatron-deepspeed](https://github.com/bigscience-workshop/megatron-deepspeed)  
5.77 stars per week over 90 weeks  
522 stars, 118 forks, 21 watches  
created 2021-07-02, last commit 2023-02-21, main language Python  


### [Megatron-DeepSpeed](https://github.com/microsoft/megatron-deepspeed) by [microsoft](https://github.com/microsoft)  
Megatron-DeepSpeed: Ongoing research training transformer language models at scale, including: BERT & GPT-2  
[https://github.com/microsoft/megatron-deepspeed](https://github.com/microsoft/megatron-deepspeed)  
4.24 stars per week over 92 weeks  
390 stars, 90 forks, 11 watches  
created 2021-06-21, last commit 2023-03-15, main language Python  


### [medical-chatgpt](https://github.com/lucidrains/medical-chatgpt) by [lucidrains](https://github.com/lucidrains)  
medical-chatgpt: Implementation of ChatGPT, but tailored towards primary care medicine, with the reward being able to collect patient histories in a thorough and efficient manner and come up with a reasonable differential diagnosis  
[https://github.com/lucidrains/medical-chatgpt](https://github.com/lucidrains/medical-chatgpt)  
16 stars per week over 15 weeks  
257 stars, 21 forks, 28 watches  
created 2022-12-10, last commit 2023-03-24, main language Python  
<sub><sup>artificial-intelligence, attention-mechanisms, deep-learning, medicine, transformers</sup></sub>


### [sgpt](https://github.com/muennighoff/sgpt) by [muennighoff](https://github.com/muennighoff)  
SGPT: GPT Sentence Embeddings for Semantic Search  
[https://github.com/muennighoff/sgpt](https://github.com/muennighoff/sgpt)  
5.03 stars per week over 58 weeks  
294 stars, 27 forks, 6 watches  
created 2022-02-11, last commit 2023-03-20, main language Jupyter Notebook  
<sub><sup>gpt, information-retrieval, language-model, large-language-models, neural-search, retrieval, semantic-search, sentence-embeddings, sgpt, text-embedding</sup></sub>


### [gpt-2-output-dataset](https://github.com/openai/gpt-2-output-dataset) by [openai](https://github.com/openai)  
gpt-2-output-dataset: Dataset of GPT-2 outputs for research in detection, biases, and more  
[https://github.com/openai/gpt-2-output-dataset](https://github.com/openai/gpt-2-output-dataset)  
7.87 stars per week over 203 weeks  
1,600 stars, 452 forks, 69 watches  
created 2019-05-03, last commit 2021-02-18, main language Python  


### [t-zero](https://github.com/bigscience-workshop/t-zero) by [bigscience-workshop](https://github.com/bigscience-workshop)  
t-zero: Reproduce results and replicate training fo T0 (Multitask Prompted Training Enables Zero-Shot Task Generalization)  
[https://github.com/bigscience-workshop/t-zero](https://github.com/bigscience-workshop/t-zero)  
5.19 stars per week over 67 weeks  
348 stars, 51 forks, 24 watches  
created 2021-12-13, last commit 2022-07-29, main language Python  


### [image-gpt](https://github.com/openai/image-gpt) by [openai](https://github.com/openai)  
openai/image-gpt  
[https://github.com/openai/image-gpt](https://github.com/openai/image-gpt)  
12 stars per week over 150 weeks  
1,824 stars, 335 forks, 79 watches  
created 2020-05-07, last commit 2020-12-04, main language Python  


This file was automatically generated on 2023-03-27.  

To curate your own github list, simply clone and change the input csv file.  

Inspired by:  
[https://github.com/vinta/awesome-python](https://github.com/vinta/awesome-python)  
[https://github.com/trananhkma/fucking-awesome-python](https://github.com/trananhkma/fucking-awesome-python)  