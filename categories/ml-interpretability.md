# dylanhogg/awesome-python  [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)  

Hand-picked awesome Python libraries and frameworks, 
with an emphasis on data and machine learning, ranked by popularity score üêç  

Checkout the interactive version: [www.awesomepython.org](https://www.awesomepython.org/) üî•  


<a href="https://github.com/slundberg)">slundberg/</a><b><a href="https://github.com/slundberg/shap">shap</a></b>  
A game theoretic approach to explain the output of any machine learning model.  
Score: 57/100, Stars: 19,138, Stars/week: 56, Forks: 2,873  


<a href="https://github.com/pytorch)">pytorch/</a><b><a href="https://github.com/pytorch/captum">captum</a></b>  
[https://captum.ai](https://captum.ai)  
Model interpretability and understanding for PyTorch  
Score: 54/100, Stars: 3,906, Stars/week: 20, Forks: 429  


<a href="https://github.com/arize-ai)">arize-ai/</a><b><a href="https://github.com/arize-ai/phoenix">phoenix</a></b>  
[https://docs.arize.com/phoenix](https://docs.arize.com/phoenix)  
ML Observability in a Notebook - Uncover Insights, Surface Problems, Monitor, and Fine Tune your Generative LLM, CV and Tabular Models  
Score: 51/100, Stars: 637, Stars/week: 24, Forks: 31  


<a href="https://github.com/seldonio)">seldonio/</a><b><a href="https://github.com/seldonio/alibi">alibi</a></b>  
[https://docs.seldon.io/projects/alibi/en/stable/](https://docs.seldon.io/projects/alibi/en/stable/)  
Algorithms for explaining machine learning models  
Score: 48/100, Stars: 2,018, Stars/week: 9, Forks: 223  


<a href="https://github.com/oegedijk)">oegedijk/</a><b><a href="https://github.com/oegedijk/explainerdashboard">explainerdashboard</a></b>  
[http://explainerdashboard.readthedocs.io](http://explainerdashboard.readthedocs.io)  
Quickly build Explainable AI dashboards that show the inner workings of so-called "blackbox" machine learning models.  
Score: 48/100, Stars: 1,674, Stars/week: 9, Forks: 219  


<a href="https://github.com/marcotcr)">marcotcr/</a><b><a href="https://github.com/marcotcr/lime">lime</a></b>  
Lime: Explaining the predictions of any machine learning classifier  
Score: 48/100, Stars: 10,629, Stars/week: 28, Forks: 1,735  


<a href="https://github.com/eleutherai)">eleutherai/</a><b><a href="https://github.com/eleutherai/pythia">pythia</a></b>  
Interpretability analysis and scaling laws to understand how knowledge develops and evolves during training in autoregressive transformers  
Score: 47/100, Stars: 1,026, Stars/week: 14, Forks: 65  


<a href="https://github.com/pair-code)">pair-code/</a><b><a href="https://github.com/pair-code/lit">lit</a></b>  
[https://pair-code.github.io/lit](https://pair-code.github.io/lit)  
The Learning Interpretability Tool: Interactively analyze ML models to understand their behavior in an extensible and framework agnostic interface.  
Score: 46/100, Stars: 3,113, Stars/week: 21, Forks: 330  


<a href="https://github.com/selfexplainml)">selfexplainml/</a><b><a href="https://github.com/selfexplainml/piml-toolbox">PiML-Toolbox</a></b>  
[https://selfexplainml.github.io/PiML-Toolbox](https://selfexplainml.github.io/PiML-Toolbox)  
PiML (Python Interpretable Machine Learning) toolbox for model development & diagnostics  
Score: 45/100, Stars: 614, Stars/week: 11, Forks: 74  


<a href="https://github.com/tensorflow)">tensorflow/</a><b><a href="https://github.com/tensorflow/lucid">lucid</a></b>  
A collection of infrastructure and tools for research in neural network interpretability.  
Score: 40/100, Stars: 4,542, Stars/week: 16, Forks: 652  


<a href="https://github.com/alignmentresearch)">alignmentresearch/</a><b><a href="https://github.com/alignmentresearch/tuned-lens">tuned-lens</a></b>  
[https://tuned-lens.readthedocs.io/en/latest/](https://tuned-lens.readthedocs.io/en/latest/)  
Tools for understanding how transformer predictions are built layer-by-layer  
Score: 39/100, Stars: 225, Stars/week: 7, Forks: 21  


<a href="https://github.com/cdpierse)">cdpierse/</a><b><a href="https://github.com/cdpierse/transformers-interpret">transformers-interpret</a></b>  
Model explainability that works seamlessly with ü§ó transformers. Explain your transformers model in just 2 lines of code.   
Score: 38/100, Stars: 1,010, Stars/week: 7, Forks: 86  


<a href="https://github.com/jalammar)">jalammar/</a><b><a href="https://github.com/jalammar/ecco">ecco</a></b>  
[https://ecco.readthedocs.io](https://ecco.readthedocs.io)  
Explain, analyze, and visualize NLP language models. Ecco creates interactive visualizations directly in Jupyter notebooks explaining the behavior of Transformer-based language models (like GPT2, BERT, RoBERTA, T5, and T0).  
Score: 35/100, Stars: 1,680, Stars/week: 12, Forks: 126  


<a href="https://github.com/eleutherai)">eleutherai/</a><b><a href="https://github.com/eleutherai/knowledge-neurons">knowledge-neurons</a></b>  
A library for finding knowledge neurons in pretrained transformer models.  
Score: 7/100, Stars: 112, Stars/week: 1, Forks: 13  


Checkout the interactive version: [www.awesomepython.org](https://www.awesomepython.org/) üî•  


This list was updated on 2023-05-12.