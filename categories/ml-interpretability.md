# Crazy Awesome Python
A selection of 14 curated ml-interpretability Python libraries and frameworks ordered by stars.  

Checkout the interactive version that you can filter and sort: 
[https://www.awesomepython.org/](https://www.awesomepython.org/)  


### [shap](https://github.com/slundberg/shap) by [slundberg](https://github.com/slundberg)  
A game theoretic approach to explain the output of any machine learning model.  
[https://github.com/slundberg/shap](https://github.com/slundberg/shap)  
56 stars per week over 337 weeks  
19,138 stars, 2,873 forks, 262 watches  
created 2016-11-22, last commit 2022-06-16, main language Jupyter Notebook  
<sub><sup>deep-learning, explainability, gradient-boosting, interpretability, machine-learning, shap, shapley</sup></sub>


### [captum](https://github.com/pytorch/captum) by [pytorch](https://github.com/pytorch)  
Model interpretability and understanding for PyTorch  
[https://captum.ai](https://captum.ai)  
[https://github.com/pytorch/captum](https://github.com/pytorch/captum)  
20 stars per week over 193 weeks  
3,906 stars, 429 forks, 212 watches  
created 2019-08-27, last commit 2023-05-02, main language Python  
<sub><sup>feature-attribution, feature-importance, interpretability, interpretable-ai, interpretable-ml</sup></sub>


### [phoenix](https://github.com/arize-ai/phoenix) by [arize-ai](https://github.com/arize-ai)  
ML Observability in a Notebook - Uncover Insights, Surface Problems, Monitor, and Fine Tune your Generative LLM, CV and Tabular Models  
[https://docs.arize.com/phoenix](https://docs.arize.com/phoenix)  
[https://github.com/arize-ai/phoenix](https://github.com/arize-ai/phoenix)  
24 stars per week over 26 weeks  
637 stars, 31 forks, 11 watches  
created 2022-11-09, last commit 2023-05-04, main language Python  
<sub><sup>ai-roi, llmops, ml-observability, mlops, model-observability</sup></sub>


### [alibi](https://github.com/seldonio/alibi) by [seldonio](https://github.com/seldonio)  
Algorithms for explaining machine learning models  
[https://docs.seldon.io/projects/alibi/en/stable/](https://docs.seldon.io/projects/alibi/en/stable/)  
[https://github.com/seldonio/alibi](https://github.com/seldonio/alibi)  
9.2 stars per week over 219 weeks  
2,018 stars, 223 forks, 45 watches  
created 2019-02-26, last commit 2023-05-03, main language Python  
<sub><sup>counterfactual, explanations, interpretability, machine-learning, xai</sup></sub>


### [explainerdashboard](https://github.com/oegedijk/explainerdashboard) by [oegedijk](https://github.com/oegedijk)  
Quickly build Explainable AI dashboards that show the inner workings of so-called "blackbox" machine learning models.  
[http://explainerdashboard.readthedocs.io](http://explainerdashboard.readthedocs.io)  
[https://github.com/oegedijk/explainerdashboard](https://github.com/oegedijk/explainerdashboard)  
9.09 stars per week over 184 weeks  
1,674 stars, 219 forks, 21 watches  
created 2019-10-30, last commit 2023-05-04, main language Python  
<sub><sup>dash, dashboard, data-scientists, explainer, inner-workings, interactive-dashboards, interactive-plots, model-predictions, permutation-importances, plotly, shap, shap-values, xai, xai-library</sup></sub>


### [lime](https://github.com/marcotcr/lime) by [marcotcr](https://github.com/marcotcr)  
Lime: Explaining the predictions of any machine learning classifier  
[https://github.com/marcotcr/lime](https://github.com/marcotcr/lime)  
28 stars per week over 373 weeks  
10,629 stars, 1,735 forks, 266 watches  
created 2016-03-15, last commit 2021-07-29, main language JavaScript  
<sub><sup>interpretable-ml</sup></sub>


### [pythia](https://github.com/eleutherai/pythia) by [eleutherai](https://github.com/eleutherai)  
Interpretability analysis and scaling laws to understand how knowledge develops and evolves during training in autoregressive transformers  
[https://github.com/eleutherai/pythia](https://github.com/eleutherai/pythia)  
14 stars per week over 71 weeks  
1,026 stars, 65 forks, 21 watches  
created 2021-12-25, last commit 2023-05-03, main language Jupyter Notebook  
<sub><sup>interpretability, interpretable-ml</sup></sub>


### [lit](https://github.com/pair-code/lit) by [pair-code](https://github.com/pair-code)  
The Learning Interpretability Tool: Interactively analyze ML models to understand their behavior in an extensible and framework agnostic interface.  
[https://pair-code.github.io/lit](https://pair-code.github.io/lit)  
[https://github.com/pair-code/lit](https://github.com/pair-code/lit)  
21 stars per week over 145 weeks  
3,113 stars, 330 forks, 71 watches  
created 2020-07-28, last commit 2022-12-02, main language TypeScript  
<sub><sup>machine-learning, natural-language-processing, visualization</sup></sub>


### [PiML-Toolbox](https://github.com/selfexplainml/piml-toolbox) by [selfexplainml](https://github.com/selfexplainml)  
PiML (Python Interpretable Machine Learning) toolbox for model development & diagnostics  
[https://selfexplainml.github.io/PiML-Toolbox](https://selfexplainml.github.io/PiML-Toolbox)  
[https://github.com/selfexplainml/piml-toolbox](https://github.com/selfexplainml/piml-toolbox)  
11 stars per week over 53 weeks  
614 stars, 74 forks, 16 watches  
created 2022-04-29, last commit 2023-05-05, main language Jupyter Notebook  
<sub><sup>interpretable-machine-learning, low-code, ml-workflow, model-diagnostics</sup></sub>


### [lucid](https://github.com/tensorflow/lucid) by [tensorflow](https://github.com/tensorflow)  
A collection of infrastructure and tools for research in neural network interpretability.  
[https://github.com/tensorflow/lucid](https://github.com/tensorflow/lucid)  
16 stars per week over 276 weeks  
4,542 stars, 652 forks, 162 watches  
created 2018-01-25, last commit 2021-03-19, main language Jupyter Notebook  
<sub><sup>colab, interpretability, jupyter-notebook, machine-learning, tensorflow, visualization</sup></sub>


### [tuned-lens](https://github.com/alignmentresearch/tuned-lens) by [alignmentresearch](https://github.com/alignmentresearch)  
Tools for understanding how transformer predictions are built layer-by-layer  
[https://tuned-lens.readthedocs.io/en/latest/](https://tuned-lens.readthedocs.io/en/latest/)  
[https://github.com/alignmentresearch/tuned-lens](https://github.com/alignmentresearch/tuned-lens)  
7.16 stars per week over 31 weeks  
225 stars, 21 forks, 5 watches  
created 2022-10-03, last commit 2023-05-02, main language Jupyter Notebook  
<sub><sup>machine-learning, pytorch, transformers</sup></sub>


### [transformers-interpret](https://github.com/cdpierse/transformers-interpret) by [cdpierse](https://github.com/cdpierse)  
Model explainability that works seamlessly with ðŸ¤— transformers. Explain your transformers model in just 2 lines of code.   
[https://github.com/cdpierse/transformers-interpret](https://github.com/cdpierse/transformers-interpret)  
6.55 stars per week over 154 weeks  
1,010 stars, 86 forks, 18 watches  
created 2020-05-27, last commit 2023-04-06, main language Jupyter Notebook  
<sub><sup>captum, computer-vision, deep-learning, explainable-ai, interpretability, machine-learning, model-explainability, natural-language-processing, neural-network, nlp, transformers, transformers-model</sup></sub>


### [ecco](https://github.com/jalammar/ecco) by [jalammar](https://github.com/jalammar)  
Explain, analyze, and visualize NLP language models. Ecco creates interactive visualizations directly in Jupyter notebooks explaining the behavior of Transformer-based language models (like GPT2, BERT, RoBERTA, T5, and T0).  
[https://ecco.readthedocs.io](https://ecco.readthedocs.io)  
[https://github.com/jalammar/ecco](https://github.com/jalammar/ecco)  
12 stars per week over 130 weeks  
1,680 stars, 126 forks, 21 watches  
created 2020-11-07, last commit 2022-01-18, main language Jupyter Notebook  
<sub><sup>explorables, language-models, natural-language-processing, nlp, pytorch, visualization</sup></sub>


### [knowledge-neurons](https://github.com/eleutherai/knowledge-neurons) by [eleutherai](https://github.com/eleutherai)  
A library for finding knowledge neurons in pretrained transformer models.  
[https://github.com/eleutherai/knowledge-neurons](https://github.com/eleutherai/knowledge-neurons)  
1.2 stars per week over 93 weeks  
112 stars, 13 forks, 3 watches  
created 2021-07-28, last commit 2021-08-11, main language Python  
<sub><sup>interpretability, transformers</sup></sub>


This file was automatically generated on 2023-05-11.  

To curate your own github list, simply clone and change the input csv file.  

Inspired by:  
[https://github.com/vinta/awesome-python](https://github.com/vinta/awesome-python)  
[https://github.com/trananhkma/fucking-awesome-python](https://github.com/trananhkma/fucking-awesome-python)  